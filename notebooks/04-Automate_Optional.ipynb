{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DataJoint U24 - Workflow DeepLabCut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Workflow Automation\n",
    "\n",
    "In the previous notebook [03-Process](./03-Process.ipynb), we ran through the workflow in detailed steps, manually adding each. The current notebook provides a more automated approach.\n",
    "\n",
    "The commands here run a workflow using example data from the [00-DownloadData](./00-DataDownload_Optional.ipynb) notebook, but note where placeholders could be changed for a different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting cbroz@dss-db.datajoint.io:3306\n"
     ]
    }
   ],
   "source": [
    "import os; from pathlib import Path\n",
    "# change to the upper level folder to detect dj_local_conf.json\n",
    "if os.path.basename(os.getcwd())=='notebooks': os.chdir('..')\n",
    "assert os.path.basename(os.getcwd())=='workflow-deeplabcut', (\"Please move to the \"\n",
    "                                                              + \"workflow directory\")\n",
    "from workflow_deeplabcut.pipeline import lab, subject, session, train, model\n",
    "from workflow_deeplabcut import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the `process.py` script to automatically loop through all `make` functions, as a shortcut for calling each individually.\n",
    "\n",
    "If you previously completed the [03-Process notebook](./03-Process.ipynb), you may want to delete the contents ingested there, to avoid duplication errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting 4 rows from `u24_dlc_session`.`session_directory`\n",
      "Deleting 4 rows from `u24_dlc_session`.`session_note`\n",
      "Deleting 4 rows from `u24_dlc_session`.`session`\n",
      "Deleting 3 rows from `u24_dlc_train`.`#training_param_set`\n",
      "Deleting 0 rows from `u24_dlc_train`.`video_set`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safemode=True # Set to false to turn off confirmation prompts\n",
    "(session.Session & 'subject=\"subject6\"').delete(safemode=safemode)\n",
    "train.TrainingParamSet.delete(safemode=safemode)\n",
    "train.VideoSet.delete(safemode=safemode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion of subjects, sessions, videos and training parameters\n",
    "\n",
    "Refer to the `user_data` folder in the workflow.\n",
    "\n",
    "1. Fill subject and session information in files `subjects.csv` and `sessions.csv`\n",
    "2. Fill in recording and parameter information in `recordings.csv` and `config_params.csv`\n",
    "    + Add both training and estimation videos to the recording list\n",
    "    + Additional columns in `config_params.csv` will be treated as model training parameters\n",
    "3. Run automatic scripts prepared in `workflow_deeplabcut.ingest` for ingestion: \n",
    "    + `ingest_subjects` for `subject.Subject`\n",
    "    + `ingest_sessions` - for session tables `Session`, `SessionDirectory`, and `SessionNote`\n",
    "    + `ingest_dlc_items` - for ...\n",
    "        - `train.ModelTrainingParamSet`\n",
    "        - `train.VideoSet` and the corresponding `File` part table\n",
    "        - `model.VideoRecording` and the corresponding `File` part table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Inserting 0 entry(s) into subject ----\n",
      "\n",
      "---- Inserting 4 entry(s) into session ----\n",
      "\n",
      "---- Inserting 4 entry(s) into session_directory ----\n",
      "\n",
      "---- Inserting 4 entry(s) into session_note ----\n",
      "\n",
      "---- Inserting 3 entry(s) into #model_training_param_set ----\n",
      "\n",
      "---- Inserting 3 entry(s) into video_set ----\n",
      "\n",
      "---- Inserting 10 entry(s) into video_set__file ----\n",
      "\n",
      "---- Inserting 1 entry(s) into video_recording ----\n",
      "\n",
      "---- Inserting 1 entry(s) into video_recording__file ----\n"
     ]
    }
   ],
   "source": [
    "from workflow_deeplabcut.ingest import ingest_subjects, ingest_sessions, ingest_dlc_items\n",
    "ingest_subjects()\n",
    "ingest_sessions()\n",
    "ingest_dlc_items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting project variables\n",
    "\n",
    "1. Set your root directory in your DataJoint config file, under `custom` as `dlc_root_data_dir`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj; dj.config.load('dj_local_conf.json')\n",
    "from element_interface.utils import find_full_path\n",
    "data_dir = find_full_path(dj.config['custom']['dlc_root_data_dir'], # root from config\n",
    "                          'from_top_tracking')                      # DLC project dir\n",
    "config_path = (data_dir / 'config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Next, we pair training files with training parameters, and launch training via `process`. \n",
    "   - Some tables may try to populate without upstream keys. \n",
    "   - Others, like `RecordingInfo` already have keys loaded.\n",
    "   - Note: DLC's model processes (e.g., Training, Evaluation) log a lot of information to the console, to quiet this, pass `verbose=False` to `process`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key={'paramset_idx':0,'training_id':0,'video_set_id':0, \n",
    "     'project_path':'from_top_tracking/'}\n",
    "train.TrainingTask.insert1(key, skip_duplicates=True)\n",
    "process.run(verbose=True, display_progress=True)\n",
    "model.RecordingInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this demo, we'll want to use an older model, so the folling function will reload the original checkpoint file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow_deeplabcut.load_demo_data import revert_checkpoint_file\n",
    "revert_checkpoint_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now to add such a model upstream key\n",
    "   - Include a user-friendly `model_name`\n",
    "   - Include the relative path for the project's `config.yaml`\n",
    "   - Add `shuffle` and `trainingsetindex`\n",
    "   - `insert_new_model` will prompt before inserting, but this can be skipped with `prompt=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DLC Model specification to be inserted ---\n",
      "\tmodel_name: FromTop-latest\n",
      "\tmodel_description: FromTop - latest snapshot\n",
      "\tscorer: DLCmobnet100fromtoptrackingFeb23shuffle1\n",
      "\ttask: from_top_tracking\n",
      "\tdate: Feb23\n",
      "\titeration: 0\n",
      "\tsnapshotindex: -1\n",
      "\tshuffle: 1\n",
      "\ttrainingsetindex: 0\n",
      "\tproject_path: from_top_tracking\n",
      "\tparamset_idx: 1\n",
      "\t-- Template/Contents of config.yaml --\n",
      "\t\tTask: from_top_tracking\n",
      "\t\tscorer: DJ\n",
      "\t\tdate: Feb23\n",
      "\t\tvideo_sets: {'/tmp/test_data/from_top_tracking/videos/train1.mp4': {'crop': '0, 500, 0, 500'}}\n",
      "\t\tbodyparts: ['head', 'bodycenter', 'tailbase']\n",
      "\t\tstart: 0\n",
      "\t\tstop: 1\n",
      "\t\tnumframes2pick: 20\n",
      "\t\tpcutoff: 0.6\n",
      "\t\tdotsize: 3\n",
      "\t\talphavalue: 0.7\n",
      "\t\tcolormap: viridis\n",
      "\t\tTrainingFraction: [0.95]\n",
      "\t\titeration: 0\n",
      "\t\tdefault_net_type: resnet_50\n",
      "\t\tsnapshotindex: -1\n",
      "\t\tbatch_size: 8\n",
      "\t\tcropping: False\n",
      "\t\tx1: 0\n",
      "\t\tx2: 640\n",
      "\t\ty1: 277\n",
      "\t\ty2: 624\n",
      "\t\tcorner2move2: [50, 50]\n",
      "\t\tmove2corner: True\n",
      "\t\tcroppedtraining: None\n",
      "\t\tdefault_augmenter: default\n",
      "\t\tidentity: None\n",
      "\t\tmaxiters: 5\n",
      "\t\tmodelprefix: \n",
      "\t\tmultianimalproject: False\n",
      "\t\tscorer_legacy: False\n",
      "\t\tshuffle: 1\n",
      "\t\tskeleton: [['bodypart1', 'bodypart2'], ['objectA', 'bodypart3']]\n",
      "\t\tskeleton_color: black\n",
      "\t\ttrain_fraction: 0.95\n",
      "\t\ttrainingsetindex: 0\n",
      "\t\tproject_path: /tmp/test_data/from_top_tracking\n",
      "\n",
      "---- Populating __model_training ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelTraining: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Populating _recording_info ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "RecordingInfo: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Populating __model_evaluation ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelEvaluation:   0%|          | 0/1 [00:00<?, ?it/s]Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['head', 'bodycenter', 'tailbase'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_from_top_trackingFeb23/from_top_tracking_DJ95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/Volumes/GoogleDrive/My '\n",
      "                 'Drive/ref/DeepLabCut/deeplabcut/pose_estimation_tensorflow/models/pretrained/mobilenet_v2_1.0_224.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'mobilenet_v2_1.0',\n",
      " 'num_joints': 3,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/tmp/test_data/from_top_tracking/dlc-models/iteration-0/from_top_trackingFeb23-trainset95shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "ModelEvaluation: 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DLC_mobnet_100_from_top_trackingFeb23shuffle1_103000  with # of training iterations: 103000\n",
      "This net has already been evaluated!\n",
      "\n",
      "---- Populating __pose_estimation ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PoseEstimation: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "model.Model.insert_new_model(model_name='FromTop-latest', \n",
    "                             dlc_config=config_path,\n",
    "                             shuffle=1,\n",
    "                             trainingsetindex=0,\n",
    "                             paramset_idx=1, \n",
    "                             prompt=True, # True is the default behavior\n",
    "                             model_description='FromTop - latest snapshot',\n",
    "                             params={\"snapshotindex\":-1})\n",
    "process.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Add a pose estimation task, and launch via `process`.\n",
    "   - Get all primary key information for a given recording\n",
    "   - Add the model and `task_mode` (i.e., load vs. trigger) to be applied\n",
    "   - Add any additional analysis parameters for `deeplabcut.analyze_videos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Populating __model_training ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelTraining: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Populating _recording_info ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RecordingInfo: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Populating __model_evaluation ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelEvaluation: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Populating __pose_estimation ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PoseEstimation:   0%|          | 0/1 [00:00<?, ?it/s]Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['head', 'bodycenter', 'tailbase'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_from_top_trackingFeb23/from_top_tracking_DJ95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/Volumes/GoogleDrive/My '\n",
      "                 'Drive/ref/DeepLabCut/deeplabcut/pose_estimation_tensorflow/models/pretrained/mobilenet_v2_1.0_224.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'mobilenet_v2_1.0',\n",
      " 'num_joints': 3,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/tmp/test_data/from_top_tracking/dlc-models/iteration-0/from_top_trackingFeb23-trainset95shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-103000 for model /tmp/test_data/from_top_tracking/dlc-models/iteration-0/from_top_trackingFeb23-trainset95shuffle1\n",
      "Starting to analyze %  /tmp/test_data/from_top_tracking/videos/test-2s.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PoseEstimation: 100%|██████████| 1/1 [00:05<00:00,  5.98s/it]\n"
     ]
    }
   ],
   "source": [
    "key=(model.VideoRecording & 'recording_id=1').fetch1('KEY')\n",
    "key.update({'model_name': 'FromTop-latest', 'task_mode': 'trigger'})\n",
    "analyze_params={'save_as_csv':True} # add any others from deeplabcut.analyze_videos\n",
    "model.PoseEstimationTask.insert_estimation_task(key,params=analyze_params)\n",
    "process.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Retrieve estimated position data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>scorer</th>\n",
       "      <th colspan=\"12\" halign=\"left\">FromTop-latest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodyparts</th>\n",
       "      <th colspan=\"4\" halign=\"left\">bodycenter</th>\n",
       "      <th colspan=\"4\" halign=\"left\">head</th>\n",
       "      <th colspan=\"4\" halign=\"left\">tailbase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coords</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246.782684</td>\n",
       "      <td>298.728088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>241.036957</td>\n",
       "      <td>316.332489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999850</td>\n",
       "      <td>256.203064</td>\n",
       "      <td>278.553314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>246.217529</td>\n",
       "      <td>299.358063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>239.048737</td>\n",
       "      <td>319.177002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999905</td>\n",
       "      <td>255.819626</td>\n",
       "      <td>280.200745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>244.459579</td>\n",
       "      <td>301.309235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>240.238800</td>\n",
       "      <td>320.525696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>255.705093</td>\n",
       "      <td>280.939056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>242.014755</td>\n",
       "      <td>302.865204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>238.536774</td>\n",
       "      <td>322.324463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>254.424484</td>\n",
       "      <td>282.015778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240.900177</td>\n",
       "      <td>303.459167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>237.967987</td>\n",
       "      <td>324.072327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>252.180603</td>\n",
       "      <td>280.899200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>248.682251</td>\n",
       "      <td>364.709869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>270.854980</td>\n",
       "      <td>371.893127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>234.899185</td>\n",
       "      <td>356.035583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>250.326385</td>\n",
       "      <td>366.870361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>271.488495</td>\n",
       "      <td>373.099884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>235.644073</td>\n",
       "      <td>356.815125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>251.634140</td>\n",
       "      <td>367.709198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>272.043884</td>\n",
       "      <td>373.402893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>236.953812</td>\n",
       "      <td>358.651459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>255.393692</td>\n",
       "      <td>364.111145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>273.417572</td>\n",
       "      <td>373.906799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>238.825363</td>\n",
       "      <td>361.561798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>257.736847</td>\n",
       "      <td>365.264008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>276.008667</td>\n",
       "      <td>373.901245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>239.148163</td>\n",
       "      <td>364.029297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "scorer    FromTop-latest                                                      \\\n",
       "bodyparts     bodycenter                                    head               \n",
       "coords                 x           y    z likelihood           x           y   \n",
       "0             246.782684  298.728088  0.0   0.999998  241.036957  316.332489   \n",
       "1             246.217529  299.358063  0.0   0.999997  239.048737  319.177002   \n",
       "2             244.459579  301.309235  0.0   0.999999  240.238800  320.525696   \n",
       "3             242.014755  302.865204  0.0   0.999999  238.536774  322.324463   \n",
       "4             240.900177  303.459167  0.0   0.999998  237.967987  324.072327   \n",
       "..                   ...         ...  ...        ...         ...         ...   \n",
       "118           248.682251  364.709869  0.0   0.999965  270.854980  371.893127   \n",
       "119           250.326385  366.870361  0.0   0.999972  271.488495  373.099884   \n",
       "120           251.634140  367.709198  0.0   0.999972  272.043884  373.402893   \n",
       "121           255.393692  364.111145  0.0   0.999979  273.417572  373.906799   \n",
       "122           257.736847  365.264008  0.0   0.999996  276.008667  373.901245   \n",
       "\n",
       "scorer                                                             \n",
       "bodyparts                    tailbase                              \n",
       "coords       z likelihood           x           y    z likelihood  \n",
       "0          0.0   0.999850  256.203064  278.553314  0.0   0.999998  \n",
       "1          0.0   0.999905  255.819626  280.200745  0.0   0.999996  \n",
       "2          0.0   0.999899  255.705093  280.939056  0.0   0.999995  \n",
       "3          0.0   0.999941  254.424484  282.015778  0.0   0.999990  \n",
       "4          0.0   0.999941  252.180603  280.899200  0.0   0.999977  \n",
       "..         ...        ...         ...         ...  ...        ...  \n",
       "118        0.0   0.999961  234.899185  356.035583  0.0   0.999996  \n",
       "119        0.0   0.999991  235.644073  356.815125  0.0   0.999989  \n",
       "120        0.0   0.999995  236.953812  358.651459  0.0   0.999977  \n",
       "121        0.0   0.999997  238.825363  361.561798  0.0   0.999885  \n",
       "122        0.0   0.999992  239.148163  364.029297  0.0   0.999962  \n",
       "\n",
       "[123 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.PoseEstimation.get_trajectory(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and next step\n",
    "\n",
    "+ This notebook runs through the workflow in an automatic manner.\n",
    "\n",
    "+ The next notebook [05-Visualization](./05-Visualization_Optional.ipynb) demonstrates how to plot this data and label videos on disk."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('ele')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "61456c693db5d9aa6731701ec9a9b08ab88a172bee0780139a3679beb166da16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
