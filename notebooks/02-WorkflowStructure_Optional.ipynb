{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DataJoint U24 - Workflow DeepLabCut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduces some useful DataJoint for exploring pipelines featuring the DeepLabCut Element.\n",
    "\n",
    "+ DataJoint needs to be configured before running this notebook (see [01-Configure](./01-Configure.ipynb)).\n",
    "+ Those familar with the structure of DataJoint workflows can skip to [03-Process](./03-Process.ipynb).\n",
    "+ The playground tutorial on [CodeBook](http://codebook.datajoint.io/) provides a more  thorough introduction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the local config, we move to the package root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.basename(os.getcwd())=='notebooks': os.chdir('..')\n",
    "assert os.path.basename(os.getcwd())=='workflow-deeplabcut', (\"Please move to the \"\n",
    "                                                              + \"workflow directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schemas, Diagrams and Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schemas are conceptually related sets of tables. By importing schemas from `workflow_deeplabcut.pipeline`, we'll declare the tables on the server with the prefix in the config (if we have permission to do so). If these tables are already declared, we'll gain access. \n",
    "\n",
    "- `dj.list_schemas()` lists all schemas a user has access to in the current database\n",
    "- `<schema>.schema.list_tables()` will provide names for each table in the format used under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "from workflow_deeplabcut.pipeline import lab, subject, session, train, model\n",
    "\n",
    "dj.list_schemas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#training_param_set',\n",
       " 'video_set',\n",
       " 'video_set__file',\n",
       " 'training_task',\n",
       " '__model_training']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.schema.list_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dj.Diagram()` plots tables and dependencies in a schema. To see additional upstream or downstream connections, add `- N` or `+ N`.\n",
    "\n",
    "- `train`: Optional schema to manage model training within DataJoint\n",
    "- `model`: Schema to manage pose estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "title": "`dj.Diagram()`: plot tables and dependencies"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238pt\" height=\"176pt\" viewBox=\"0.00 0.00 238.00 176.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 172)\">\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-172 234,-172 234,4 -4,4\"/>\n<!-- train.TrainingTask -->\n<g id=\"node1\" class=\"node\">\n<title>train.TrainingTask</title>\n<g id=\"a_node1\"><a xlink:title=\"→ train.VideoSet\r\n→ train.TrainingParamSet\r\ntraining_id          \r\n------------------------------\r\nmodel_prefix=&quot;&quot;      \r\nproject_path=&quot;&quot;      \r\n\">\n<polygon fill=\"#00ff00\" fill-opacity=\"0.188235\" stroke=\"#00ff00\" stroke-opacity=\"0.188235\" points=\"115,-97 4,-97 4,-62 115,-62 115,-97\"/>\n<text text-anchor=\"start\" x=\"12\" y=\"-77.4\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"12.00\" fill=\"darkgreen\">train.TrainingTask</text>\n</a>\n</g>\n</g>\n<!-- train.ModelTraining -->\n<g id=\"node4\" class=\"node\">\n<title>train.ModelTraining</title>\n<g id=\"a_node4\"><a xlink:title=\"→ train.TrainingTask\r\n------------------------------\r\nlatest_snapshot      \r\nconfig_template      \r\n\">\n<ellipse fill=\"#ff0000\" fill-opacity=\"0.125490\" stroke=\"#ff0000\" stroke-opacity=\"0.125490\" cx=\"59.5\" cy=\"-13\" rx=\"13\" ry=\"13\"/>\n<text text-anchor=\"middle\" x=\"59.5\" y=\"-9.9\" font-family=\"arial\" font-size=\"12.00\" fill=\"#7f0000\" fill-opacity=\"0.627451\">train.ModelTraining</text>\n</a>\n</g>\n</g>\n<!-- train.TrainingTask&#45;&gt;train.ModelTraining -->\n<g id=\"edge1\" class=\"edge\">\n<title>train.TrainingTask-&gt;train.ModelTraining</title>\n<path fill=\"none\" stroke=\"#000000\" stroke-width=\"2\" stroke-opacity=\"0.250980\" d=\"M59.5,-61.89C59.5,-50.69 59.5,-36.17 59.5,-26.07\"/>\n</g>\n<!-- train.VideoSet.File -->\n<g id=\"node2\" class=\"node\">\n<title>train.VideoSet.File</title>\n<g id=\"a_node2\"><a xlink:title=\"→ train.VideoSet\r\nfile_path            \r\n\">\n<polygon fill=\"transparent\" stroke=\"transparent\" points=\"230,-89 133,-89 133,-70 230,-70 230,-89\"/>\n<text text-anchor=\"start\" x=\"141\" y=\"-78\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"10.00\">train.VideoSet.File</text>\n</a>\n</g>\n</g>\n<!-- train.VideoSet -->\n<g id=\"node3\" class=\"node\">\n<title>train.VideoSet</title>\n<g id=\"a_node3\"><a xlink:title=\"video_set_id         \r\n\">\n<polygon fill=\"#00ff00\" fill-opacity=\"0.188235\" stroke=\"#00ff00\" stroke-opacity=\"0.188235\" points=\"227.5,-168 135.5,-168 135.5,-133 227.5,-133 227.5,-168\"/>\n<text text-anchor=\"start\" x=\"143.5\" y=\"-148.4\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"12.00\" fill=\"darkgreen\">train.VideoSet</text>\n</a>\n</g>\n</g>\n<!-- train.VideoSet&#45;&gt;train.TrainingTask -->\n<g id=\"edge2\" class=\"edge\">\n<title>train.VideoSet-&gt;train.TrainingTask</title>\n<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M152.28,-132.97C133.1,-122.13 108.12,-108 88.91,-97.13\"/>\n</g>\n<!-- train.VideoSet&#45;&gt;train.VideoSet.File -->\n<g id=\"edge3\" class=\"edge\">\n<title>train.VideoSet-&gt;train.VideoSet.File</title>\n<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M181.5,-132.8C181.5,-119.08 181.5,-100.19 181.5,-89.27\"/>\n</g>\n<!-- train.TrainingParamSet -->\n<g id=\"node5\" class=\"node\">\n<title>train.TrainingParamSet</title>\n<g id=\"a_node5\"><a xlink:title=\"paramset_idx         \r\n------------------------------\r\nparamset_desc        \r\nparam_set_hash       \r\nparams               \r\nUNIQUE INDEX (param_set_hash)\r\n\">\n<polygon fill=\"#000000\" fill-opacity=\"0.125490\" stroke=\"transparent\" points=\"117.5,-168 1.5,-168 1.5,-133 117.5,-133 117.5,-168\"/>\n<text text-anchor=\"start\" x=\"9.5\" y=\"-149\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"10.00\">train.TrainingParamSet</text>\n</a>\n</g>\n</g>\n<!-- train.TrainingParamSet&#45;&gt;train.TrainingTask -->\n<g id=\"edge4\" class=\"edge\">\n<title>train.TrainingParamSet-&gt;train.TrainingTask</title>\n<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M59.5,-132.8C59.5,-121.95 59.5,-107.87 59.5,-97.05\"/>\n</g>\n</g>\n</svg>",
      "text/plain": [
       "<datajoint.diagram.Diagram at 0x7f86e3d552e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dj.Diagram(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"835pt\" height=\"231pt\" viewBox=\"0.00 0.00 834.50 231.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 227)\">\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-227 830.5,-227 830.5,4 -4,4\"/>\n<!-- model.ModelEvaluation -->\n<g id=\"node1\" class=\"node\">\n<title>model.ModelEvaluation</title>\n<g id=\"a_node1\"><a xlink:title=\"→ model.Model\r------------------------------\rtrain_iterations     \rtrain_error=null     \rtest_error=null      \rp_cutoff=null        \rtrain_error_p=null   \rtest_error_p=null    \r\">\n<ellipse fill=\"#ff0000\" fill-opacity=\"0.125490\" stroke=\"#ff0000\" stroke-opacity=\"0.125490\" cx=\"243\" cy=\"-134.5\" rx=\"13\" ry=\"13\"/>\n<text text-anchor=\"middle\" x=\"243\" y=\"-131.4\" font-family=\"arial\" font-size=\"12.00\" fill=\"#7f0000\" fill-opacity=\"0.627451\">model.ModelEvaluation</text>\n</a>\n</g>\n</g>\n<!-- model.PoseEstimationTask -->\n<g id=\"node2\" class=\"node\">\n<title>model.PoseEstimationTask</title>\n<g id=\"a_node2\"><a xlink:title=\"→ model.VideoRecording\r→ model.Model\r------------------------------\rtask_mode=&quot;load&quot;     \rpose_estimation_output_dir=&quot;&quot; \rpose_estimation_params=null \r\">\n<polygon fill=\"#00ff00\" fill-opacity=\"0.188235\" stroke=\"#00ff00\" stroke-opacity=\"0.188235\" points=\"493.5,-152 332.5,-152 332.5,-117 493.5,-117 493.5,-152\"/>\n<text text-anchor=\"middle\" x=\"413\" y=\"-131.4\" font-family=\"arial\" font-size=\"12.00\" fill=\"darkgreen\">model.PoseEstimationTask</text>\n</a>\n</g>\n</g>\n<!-- model.PoseEstimation -->\n<g id=\"node7\" class=\"node\">\n<title>model.PoseEstimation</title>\n<g id=\"a_node7\"><a xlink:title=\"→ model.PoseEstimationTask\r------------------------------\rpose_estimation_time \r\">\n<ellipse fill=\"#ff0000\" fill-opacity=\"0.125490\" stroke=\"#ff0000\" stroke-opacity=\"0.125490\" cx=\"357\" cy=\"-68\" rx=\"13\" ry=\"13\"/>\n<text text-anchor=\"middle\" x=\"357\" y=\"-64.9\" font-family=\"arial\" font-size=\"12.00\" fill=\"#7f0000\" fill-opacity=\"0.627451\">model.PoseEstimation</text>\n</a>\n</g>\n</g>\n<!-- model.PoseEstimationTask&#45;&gt;model.PoseEstimation -->\n<g id=\"edge1\" class=\"edge\">\n<title>model.PoseEstimationTask-&gt;model.PoseEstimation</title>\n<path fill=\"none\" stroke=\"#000000\" stroke-width=\"2\" stroke-opacity=\"0.250980\" d=\"M398.58,-116.89C387.95,-104.65 373.87,-88.44 365.13,-78.37\"/>\n</g>\n<!-- model.VideoRecording.File -->\n<g id=\"node3\" class=\"node\">\n<title>model.VideoRecording.File</title>\n<g id=\"a_node3\"><a xlink:title=\"→ model.VideoRecording\rfile_id              \r------------------------------\rfile_path            \r\">\n<polygon fill=\"transparent\" stroke=\"transparent\" points=\"824,-144 690,-144 690,-125 824,-125 824,-144\"/>\n<text text-anchor=\"start\" x=\"698\" y=\"-133\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"10.00\">model.VideoRecording.File</text>\n</a>\n</g>\n</g>\n<!-- model.Model -->\n<g id=\"node4\" class=\"node\">\n<title>model.Model</title>\n<g id=\"a_node4\"><a xlink:title=\"model_name           \r------------------------------\rtask                 \rdate                 \riteration            \rsnapshotindex        \rshuffle              \rtrainingsetindex     \rscorer               \rconfig_template      \rproject_path         \rmodel_prefix=&quot;&quot;      \rmodel_description=&quot;&quot; \r→ [nullable] train.TrainingParamSet\rUNIQUE INDEX (task, date, iteration, shuffle, snapshotindex, trainingsetindex)\r\">\n<polygon fill=\"#00ff00\" fill-opacity=\"0.188235\" stroke=\"#00ff00\" stroke-opacity=\"0.188235\" points=\"190,-223 104,-223 104,-188 190,-188 190,-223\"/>\n<text text-anchor=\"start\" x=\"112\" y=\"-203.4\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"12.00\" fill=\"darkgreen\">model.Model</text>\n</a>\n</g>\n</g>\n<!-- model.Model&#45;&gt;model.ModelEvaluation -->\n<g id=\"edge2\" class=\"edge\">\n<title>model.Model-&gt;model.ModelEvaluation</title>\n<path fill=\"none\" stroke=\"#000000\" stroke-width=\"2\" stroke-opacity=\"0.250980\" d=\"M170.24,-187.8C190.22,-173.44 218.07,-153.42 232.85,-142.79\"/>\n</g>\n<!-- model.Model&#45;&gt;model.PoseEstimationTask -->\n<g id=\"edge3\" class=\"edge\">\n<title>model.Model-&gt;model.PoseEstimationTask</title>\n<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M190.03,-193.34C233.12,-182.16 299.91,-164.84 349.16,-152.06\"/>\n</g>\n<!-- model.Model.BodyPart -->\n<g id=\"node10\" class=\"node\">\n<title>model.Model.BodyPart</title>\n<g id=\"a_node10\"><a xlink:title=\"→ model.Model\r→ model.BodyPart\r\">\n<polygon fill=\"transparent\" stroke=\"transparent\" points=\"153,-144 37,-144 37,-125 153,-125 153,-144\"/>\n<text text-anchor=\"middle\" x=\"95\" y=\"-132\" font-family=\"arial\" font-size=\"10.00\">model.Model.BodyPart</text>\n</a>\n</g>\n</g>\n<!-- model.Model&#45;&gt;model.Model.BodyPart -->\n<g id=\"edge4\" class=\"edge\">\n<title>model.Model-&gt;model.Model.BodyPart</title>\n<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M134.41,-187.8C124.07,-174.08 109.84,-155.19 101.61,-144.27\"/>\n</g>\n<!-- model.RecordingInfo -->\n<g id=\"node5\" class=\"node\">\n<title>model.RecordingInfo</title>\n<g id=\"a_node5\"><a xlink:title=\"→ model.VideoRecording\r------------------------------\rpx_height            \rpx_width             \rnframes              \rfps=null             \rrecording_datetime=null \rrecording_duration   \r\">\n<ellipse fill=\"#00007f\" fill-opacity=\"0.250980\" stroke=\"#00007f\" stroke-opacity=\"0.250980\" cx=\"592\" cy=\"-134.5\" rx=\"80\" ry=\"17.5\"/>\n<text text-anchor=\"middle\" x=\"592\" y=\"-131.4\" font-family=\"arial\" font-size=\"12.00\" fill=\"#00007f\" fill-opacity=\"0.627451\">model.RecordingInfo</text>\n</a>\n</g>\n</g>\n<!-- model.VideoRecording -->\n<g id=\"node6\" class=\"node\">\n<title>model.VideoRecording</title>\n<g id=\"a_node6\"><a xlink:title=\"→ session.Session\rrecording_id         \r------------------------------\r→ `u24_dlc_lab`.`#device`\r\">\n<polygon fill=\"#00ff00\" fill-opacity=\"0.188235\" stroke=\"#00ff00\" stroke-opacity=\"0.188235\" points=\"826.5,-223 687.5,-223 687.5,-188 826.5,-188 826.5,-223\"/>\n<text text-anchor=\"start\" x=\"695.5\" y=\"-203.4\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"12.00\" fill=\"darkgreen\">model.VideoRecording</text>\n</a>\n</g>\n</g>\n<!-- model.VideoRecording&#45;&gt;model.PoseEstimationTask -->\n<g id=\"edge5\" class=\"edge\">\n<title>model.VideoRecording-&gt;model.PoseEstimationTask</title>\n<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M687.39,-190.54C631.34,-179.29 552.48,-163.48 493.68,-151.68\"/>\n</g>\n<!-- model.VideoRecording&#45;&gt;model.VideoRecording.File -->\n<g id=\"edge6\" class=\"edge\">\n<title>model.VideoRecording-&gt;model.VideoRecording.File</title>\n<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M757,-187.8C757,-174.08 757,-155.19 757,-144.27\"/>\n</g>\n<!-- model.VideoRecording&#45;&gt;model.RecordingInfo -->\n<g id=\"edge7\" class=\"edge\">\n<title>model.VideoRecording-&gt;model.RecordingInfo</title>\n<path fill=\"none\" stroke=\"#000000\" stroke-width=\"2\" stroke-opacity=\"0.250980\" d=\"M717.48,-187.97C690.02,-176.49 653.75,-161.32 627.27,-150.25\"/>\n</g>\n<!-- model.PoseEstimation.BodyPartPosition -->\n<g id=\"node8\" class=\"node\">\n<title>model.PoseEstimation.BodyPartPosition</title>\n<g id=\"a_node8\"><a xlink:title=\"→ model.PoseEstimation\r→ model.Model.BodyPart\r------------------------------\rframe_index          \rx_pos                \ry_pos                \rz_pos=null           \rlikelihood           \r\">\n<polygon fill=\"transparent\" stroke=\"transparent\" points=\"454,-19 260,-19 260,0 454,0 454,-19\"/>\n<text text-anchor=\"middle\" x=\"357\" y=\"-7\" font-family=\"arial\" font-size=\"10.00\">model.PoseEstimation.BodyPartPosition</text>\n</a>\n</g>\n</g>\n<!-- model.PoseEstimation&#45;&gt;model.PoseEstimation.BodyPartPosition -->\n<g id=\"edge8\" class=\"edge\">\n<title>model.PoseEstimation-&gt;model.PoseEstimation.BodyPartPosition</title>\n<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M357,-54.74C357,-43.97 357,-28.56 357,-19.06\"/>\n</g>\n<!-- model.BodyPart -->\n<g id=\"node9\" class=\"node\">\n<title>model.BodyPart</title>\n<g id=\"a_node9\"><a xlink:title=\"body_part            \r------------------------------\rbody_part_description=&quot;&quot; \r\">\n<polygon fill=\"#000000\" fill-opacity=\"0.125490\" stroke=\"transparent\" points=\"86,-223 0,-223 0,-188 86,-188 86,-223\"/>\n<text text-anchor=\"start\" x=\"8\" y=\"-204\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"10.00\">model.BodyPart</text>\n</a>\n</g>\n</g>\n<!-- model.BodyPart&#45;&gt;model.Model.BodyPart -->\n<g id=\"edge9\" class=\"edge\">\n<title>model.BodyPart-&gt;model.Model.BodyPart</title>\n<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M55.59,-187.8C65.93,-174.08 80.16,-155.19 88.39,-144.27\"/>\n</g>\n<!-- model.Model.BodyPart&#45;&gt;model.PoseEstimation.BodyPartPosition -->\n<g id=\"edge10\" class=\"edge\">\n<title>model.Model.BodyPart-&gt;model.PoseEstimation.BodyPartPosition</title>\n<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M113.42,-124.85C161.53,-102.27 290.51,-41.71 338.6,-19.14\"/>\n</g>\n</g>\n</svg>",
      "text/plain": [
       "<datajoint.diagram.Diagram at 0x7f812fd085e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dj.Diagram(model) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Types\n",
    "\n",
    "- **Manual table**: green box, manually inserted table, expect new entries daily, e.g. Subject, ProbeInsertion.  \n",
    "- **Lookup table**: gray box, pre inserted table, commonly used for general facts or parameters. e.g. Strain, ClusteringMethod, ClusteringParamSet.  \n",
    "- **Imported table**: blue oval, auto-processing table, the processing depends on the importing of external files. e.g. process of Clustering requires output files from kilosort2.  \n",
    "- **Computed table**: red circle, auto-processing table, the processing does not depend on files external to the database, commonly used for     \n",
    "- **Part table**: plain text, as an appendix to the master table, all the part entries of a given master entry represent a intact set of the master entry. e.g. Unit of a CuratedClustering.\n",
    "\n",
    "### Table Links\n",
    "\n",
    "- **One-to-one primary**: thick solid line, share the exact same primary key, meaning the child table inherits all the primary key fields from the parent table as its own primary key.     \n",
    "- **One-to-many primary**: thin solid line, inherit the primary key from the parent table, but have additional field(s) as part of the primary key as well\n",
    "- **Secondary dependency**: dashed line, the child table inherits the primary key fields from parent table as its own secondary attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Table Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- `<table>()` show table contents\n",
    "- `heading` shows attribute definitions\n",
    "- `describe()` show table defintiion with foreign key references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "Each datajoint table class inside the module corresponds to a table inside the schema. For example, the class `ephys.EphysRecording` correponds to the table `_ephys_recording` in the schema `neuro_ephys` in the database."
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    <style type=\"text/css\">\n",
       "        .Relation{\n",
       "            border-collapse:collapse;\n",
       "        }\n",
       "        .Relation th{\n",
       "            background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "            font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "        }\n",
       "        .Relation td{\n",
       "            padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "        }\n",
       "        .Relation tr:nth-child(odd){\n",
       "            background: #ffffff;\n",
       "        }\n",
       "        .Relation tr:nth-child(even){\n",
       "            background: #f3f1ff;\n",
       "        }\n",
       "        /* Tooltip container */\n",
       "        .djtooltip {\n",
       "        }\n",
       "        /* Tooltip text */\n",
       "        .djtooltip .djtooltiptext {\n",
       "            visibility: hidden;\n",
       "            width: 120px;\n",
       "            background-color: black;\n",
       "            color: #fff;\n",
       "            text-align: center;\n",
       "            padding: 5px 0;\n",
       "            border-radius: 6px;\n",
       "            /* Position the tooltip text - see examples below! */\n",
       "            position: absolute;\n",
       "            z-index: 1;\n",
       "        }\n",
       "        #primary {\n",
       "            font-weight: bold;\n",
       "            color: black;\n",
       "        }\n",
       "        #nonprimary {\n",
       "            font-weight: normal;\n",
       "            color: white;\n",
       "        }\n",
       "\n",
       "        /* Show the tooltip text when you mouse over the tooltip container */\n",
       "        .djtooltip:hover .djtooltiptext {\n",
       "            visibility: visible;\n",
       "        }\n",
       "    </style>\n",
       "    \n",
       "    <b></b>\n",
       "        <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "        <table border=\"1\" class=\"Relation\">\n",
       "            <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">subject</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">session_datetime</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">recording_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">file_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">file_path</p>\n",
       "                            <span class=\"djtooltiptext\">filepath of video, relative to root data directory</span>\n",
       "                        </div> </th> </tr> </thead>\n",
       "            <tbody> <tr>  </tr> </tbody>\n",
       "        </table>\n",
       "        \n",
       "        <p>Total: 0</p></div>\n",
       "        "
      ],
      "text/plain": [
       "*subject    *session_datet *recording_id  *file_id    file_path    \n",
       "+---------+ +------------+ +------------+ +---------+ +-----------+\n",
       "\n",
       " (Total: 0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.VideoRecording.File()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "`heading`: show table attributes regardless of foreign key references."
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# \n",
       "model_name           : varchar(64)                  # user-friendly model name\n",
       "---\n",
       "task                 : varchar(32)                  # task in the config yaml\n",
       "date                 : varchar(16)                  # date in the config yaml\n",
       "iteration            : int                          # iteration/version of this model\n",
       "snapshotindex        : int                          # which snapshot for prediction (if -1, latest)\n",
       "shuffle              : int                          # which shuffle of the training dataset\n",
       "trainingsetindex     : int                          # which training set fraction to generate model\n",
       "scorer               : varchar(64)                  # scorer/network name - DLC's GetScorerName()\n",
       "config_template      : longblob                     # dictionary of the config for analyze_videos()\n",
       "project_path         : varchar(255)                 # DLC's project_path in config relative to root\n",
       "model_prefix=\"\"      : varchar(32)                  # \n",
       "model_description=\"\" : varchar(1000)                # \n",
       "paramset_idx=null    : smallint                     # "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.Model.heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Specification for a DLC model training instance\n",
      "-> train.VideoSet\n",
      "-> train.TrainingParamSet\n",
      "training_id          : int                          \n",
      "---\n",
      "model_prefix=\"\"      : varchar(32)                  \n",
      "project_path=\"\"      : varchar(255)                 # DLC's project_path in config relative to root\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Specification for a DLC model training instance\\n-> train.VideoSet\\n-> train.TrainingParamSet\\ntraining_id          : int                          \\n---\\nmodel_prefix=\"\"      : varchar(32)                  \\nproject_path=\"\"      : varchar(255)                 # DLC\\'s project_path in config relative to root\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.TrainingTask.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "title": "ephys"
   },
   "source": [
    "## Other Elements installed with the workflow\n",
    "\n",
    "- [`lab`](https://github.com/datajoint/element-lab): lab management related information, such as Lab, User, Project, Protocol, Source.\n",
    "- [`subject`](https://github.com/datajoint/element-animal): general animal information, User, Genetic background, Death etc.\n",
    "- [`session`](https://github.com/datajoint/element-session): General information of experimental sessions.\n",
    "\n",
    "For more information about these Elements, see [workflow session](https://github.com/datajoint/workflow-session)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(lab) + dj.Diagram(subject) + dj.Diagram(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "title": "[session](https://github.com/datajoint/element-session): experimental session information"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> subject.Subject\n",
      "session_datetime     : datetime                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'-> subject.Subject\\nsession_datetime     : datetime                     \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.Session.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and next step\n",
    "\n",
    "- This notebook introduced the overall structures of the schemas and tables in the workflow and relevant tools to explore the schema structure and table definitions.\n",
    "\n",
    "- The [next notebook](./03-Process.ipynb) will introduce the detailed steps to run through `workflow-deeplabcut`."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('ele')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "61456c693db5d9aa6731701ec9a9b08ab88a172bee0780139a3679beb166da16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
